{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mirnaphilip/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mirnaphilip/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mirnaphilip/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer and stop words\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the convention database\n",
    "convention_db_path = '/Users/mirnaphilip/Desktop/Applied Text Minning/m4/Data/2020_Conventions.db'\n",
    "convention_db = sqlite3.connect(convention_db_path)\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['skip content company career press freelancer blog Ã— service transcription caption foreign subtitle translation freelancer contact login Â« return transcript library home transcript category transcript 2020 election transcript classic speech transcript congressional testimony hearing transcript debate transcript donald trump transcript entertainment transcript financial transcript interview transcript political transcript press conference transcript speech transcript sport transcript technology transcript aug 21 2020 2020 democratic national convention dnc night 4 transcript rev â€º blog â€º transcript â€º 2020 election transcript â€º 2020 democratic national convention dnc night 4 transcript night 4 2020 democratic national convention dnc august 20 read full transcript event transcribe content try rev free save time transcribing captioning subtitling',\n",
       "   'Democratic'],\n",
       "  ['â€™ calling full session 48th quadrennial national convention democratic party order welcome final session historic memorable convention â€™ called 48th quadrennial democratic national convention order',\n",
       "   'Democratic'],\n",
       "  ['every four year come together reaffirm democracy year â€™ come save',\n",
       "   'Democratic'],\n",
       "  ['fight perfect union fighting soul country life right fight real',\n",
       "   'Democratic'],\n",
       "  ['must come together defeat donald trump elect joe biden kamala harris next president vice president',\n",
       "   'Democratic']],\n",
       " 'Retrieved 2541 rows from the database.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to clean and tokenize text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Part 1: Exploratory Naive Bayes\n",
    "convention_data = []\n",
    "\n",
    "# Query to retrieve convention speeches and their associated party\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT text, party\n",
    "    FROM conventions\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Check if the query results contain data\n",
    "query_results = query_results.fetchall()\n",
    "if not query_results:\n",
    "    data_status = \"The database or table is empty.\"\n",
    "else:\n",
    "    for row in query_results:\n",
    "        cleaned_text = preprocess_text(row[0])\n",
    "        party = row[1]\n",
    "        convention_data.append([cleaned_text, party])\n",
    "    data_status = f\"Retrieved {len(query_results)} rows from the database.\"\n",
    "\n",
    "# Close the database connection\n",
    "convention_db.close()\n",
    "\n",
    "convention_data[:5], data_status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['search warrant executed home mark patricia mccloskey', 'Republican'],\n",
       " ['never say often loudly enough immigrant refugee revitalize renew america â€™ something take granted â€™ something cherish fight god bless god bless united state america',\n",
       "  'Democratic'],\n",
       " ['sick 10 day really bad got everything besides cough recovered work month half work local county jail',\n",
       "  'Republican'],\n",
       " ['already built 300 mile border wall adding 10 new mile every single week wall soon complete working beyond wildest expectation joined evening member border patrol union representing country â€™ courageous border agent thank much thank brave brave people see country love law enforcement really love respect learned tennessee valley authority laid hundred american worker forced train lower paid foreign replacement promptly removed chairman board talented american worker rehired back providing power georgia alabama tennessee kentucky mississippi north carolina virginia',\n",
       "  'Republican'],\n",
       " ['missouri', 'Republican'],\n",
       " ['wish every american could see president trump negotiates behalf â€™ watched president trump charm chancellor germany insisting germany pay nato obligation proud witness president trump say foreign leader â€œ â€™ blame wanting america pay security actually respect negotiating president stop â€™ let american taxpayer taken advantage â€ donald trump â€™ administration always made clear priority american people â€™ security â€™ job leader put people first â€™ seen strategy succeeded four short year donald trump led even washington democrat agree chinese threat trade deal benefit america first alliance share responsibility',\n",
       "  'Republican'],\n",
       " ['represents concern healthcare', 'Democratic'],\n",
       " ['quit law firm asked job become public defender â€™ sort got involved politics',\n",
       "  'Democratic'],\n",
       " ['postal service deliver suspicious became even confronting covid19 virus hit u united state',\n",
       "  'Democratic'],\n",
       " ['fellow american country many u fought hard right say many struggling today harlem danang may say conviction country',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2188 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All assertions passed.\n"
     ]
    }
   ],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the feature words.\n",
    "    \n",
    "    Args: \n",
    "        * text: a piece of text in a continuous string. Assumes\n",
    "        text has been cleaned and case folded.\n",
    "        * fw: the *feature words* that we're considering. A word \n",
    "        in `text` must be in fw in order to be returned. This \n",
    "        prevents us from considering very rarely occurring words.\n",
    "    \n",
    "    Returns: \n",
    "        A dictionary with the words in `text` that appear in `fw`. \n",
    "        Words are only counted once. \n",
    "        If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "        then this would return a dictionary of \n",
    "        {'quick' : True,\n",
    "         'fox' :    True}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary to hold the feature words\n",
    "    ret_dict = dict()\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Iterate over each word in the text\n",
    "    for word in words:\n",
    "        # If the word is in the feature words set, add it to the dictionary\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    \n",
    "    return ret_dict\n",
    "\n",
    "# Example usage with assertions:\n",
    "feature_words = {'donald', 'president', 'people', 'american', 'america'}\n",
    "\n",
    "assert len(feature_words) > 0\n",
    "\n",
    "assert conv_features(\"donald is the president\", feature_words) == {'donald': True, 'president': True}\n",
    "assert conv_features(\"people are american in america\", feature_words) == {'america': True, 'american': True, 'people': True}\n",
    "\n",
    "print(\"All assertions passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  donald = True           Republ : Democr =      2.5 : 1.0\n",
      "                american = True           Republ : Democr =      2.4 : 1.0\n",
      "                 america = True           Republ : Democr =      2.3 : 1.0\n",
      "               president = True           Republ : Democr =      1.9 : 1.0\n",
      "                  people = True           Republ : Democr =      1.3 : 1.0\n",
      "               president = None           Democr : Republ =      1.3 : 1.0\n",
      "                american = None           Democr : Republ =      1.2 : 1.0\n",
      "                 america = None           Democr : Republ =      1.2 : 1.0\n",
      "                  donald = None           Democr : Republ =      1.1 : 1.0\n",
      "                  people = None           Democr : Republ =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "_Upon examining the Naive Bayes classifier and its most informative features, it is evident that words like \"donald,\" \"american,\" \"america,\" \"president,\" and \"people\" are strongly associated with the Republican party, reflecting the prominence of figures like Donald Trump and themes of national identity. Interestingly, these same words appear with lower likelihoods for the Democratic party, suggesting a nuanced overlap in political rhetoric. The classifier's accuracy of 60% indicates moderate performance, highlighting the challenges in distinguishing political discourse based solely on word frequencies. With a word cutoff of 5, yielding 2188 features, the model effectively reduces noise but may miss some informative words. Future improvements could involve more sophisticated text analysis techniques and models to enhance accuracy._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"/Users/mirnaphilip/Desktop/Applied Text Minning/m4/Data/congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming\n",
    "\n",
    "# Close the database connection\n",
    "cong_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['brook join alabama delegation voting flawed funding bill httptco3cwjiwysnq',\n",
       "  'Republican'],\n",
       " ['brook senate democrat allowing president give american â€™ job illegals securetheborder httpstcomzteax8xs6',\n",
       "  'Republican'],\n",
       " ['nasa square event sat 11am â€“ 4pm stop amp hear incredible work done al05 downtownhsv httptcor9zy8wmepa',\n",
       "  'Republican'],\n",
       " ['trouble socialism eventually run people money margaret thatcher httpstcox97g7wzqwj',\n",
       "  'Republican'],\n",
       " ['trouble socialism eventually run people money â€“ thatcher shell sorely missed httptcoz8gbndquh8',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to preprocess the tweet text (clean and tokenize)\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode('utf-8')\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Process each tweet in the results\n",
    "tweet_data = []\n",
    "for candidate, party, tweet_text in results:\n",
    "    cleaned_text = preprocess_text(tweet_text)\n",
    "    tweet_data.append([cleaned_text, party])\n",
    "\n",
    "# Display the first few rows of the processed tweet data\n",
    "tweet_data[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care woman praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump think easy student overwhelmed crushing burden debt pay student loan trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: â€™ grateful first responder rescue personnel firefighter police volunteer working tirelessly keep people safe provide muchneeded help putting life line httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: let â€™ make even greater kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot â€™ 7000 nonmath major room ðŸ˜‚ help u get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potus â€™ plan expand offshore drilling opened public 60 day march 9 share oppose proposed program directly trump administration comment made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastla â€™ 22 year eastside commitment amp saluted community leader last night â€™ award dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample:\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp\n",
    "    \n",
    "    # Get the estimated party\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Republican, Estimated: Republican, Count: 327\n",
      "Actual: Republican, Estimated: Democratic, Count: 3964\n",
      "Actual: Democratic, Estimated: Republican, Count: 501\n",
      "Actual: Democratic, Estimated: Democratic, Count: 5210\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "for actual_party in results:\n",
    "    for estimated_party in results[actual_party]:\n",
    "        print(f\"Actual: {actual_party}, Estimated: {estimated_party}, Count: {results[actual_party][estimated_party]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Upon analyzing the results of the Naive Bayes classifier applied to congressional tweets, a few observations stand out. The classifier appears to be biased towards classifying tweets as \"Democratic,\" as evidenced by the significantly higher count of tweets estimated as Democratic regardless of their actual party affiliation. Specifically, the model classified a substantial number of Republican tweets incorrectly as Democratic (3964 instances) compared to the reverse (501 instances). This discrepancy suggests that the features selected might be more representative of Democratic language patterns or that the classifier struggles with certain linguistic nuances in Republican tweets. Additionally, the overall accuracy is moderate, indicating that while the classifier captures some distinctions between the parties, it still faces challenges in reliably distinguishing between them based solely on tweet content. This analysis highlights the importance of feature selection and potential improvements in the preprocessing and model training steps to enhance classification accuracy._ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
